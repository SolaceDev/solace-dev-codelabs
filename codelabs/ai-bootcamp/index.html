
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>AI Bootcamp - Solace HQ</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14" ga4id=""></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  codelab-ga4id=""
                  id="ai-bootcamp"
                  title="AI Bootcamp - Solace HQ"
                  environment="web"
                  feedback-link="https://github.com/SolaceDev/solace-dev-codelabs/blob/master/markdown/ai-bootcamp">
    
      <google-codelab-step label="Introduction" duration="1">
        <p>Welcome to the HQ AI Bootcamps to come up to speed with Solace Agent Mesh.</p>
<p>Follow the steps in this codelab to get started with the Enterprise Image for SAM.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Load Enterprise Image" duration="2">
        <ol type="1">
<li>Download the enterprise image from <a href="https://products.solace.com/" target="_blank">https://products.solace.com/</a></li>
<li>Load the image into your local docker</li>
</ol>
<pre><code>docker load -i path/to/solace-agent-mesh-enterprise-{version}.tar.gz
</code></pre>
<p>On successful loading, check the list of existing images</p>
<pre><code>docker images 
</code></pre>
<aside class="special"><p> Tip: you can rename the image and tag as follows</p>
<pre><code>docker tag &lt;original_name&gt;:&lt;original_tag&gt; solace-agent-mesh-enterprise:&lt;version&gt;
</code></pre>
</aside>
<aside class="special"><p> If you don&#39;t have <code>docker</code> you can use <code>podman</code> and replace every docker command with podman</p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Install SAM CLI" duration="5">
        <p>While you dont technically need the SAM cli to work with the enterprise edition, this will facilitate creating the files you need. We will make use of the scaffolding commands to initialize and create SAM components.</p>
<ol type="1">
<li>Create working directory<pre><code>mkdir sam-bootcamp
cd sam-bootcamp
</code></pre>
</li>
<li>Setup Python virtual environment<pre><code>python3.12 -m venv venv
</code></pre>
<aside class="special"><p> Depending on how you installed python on your machine, this command could be <code>python3</code></p>
</aside>
<aside class="special"><p> Note: If you dont have <code>venv</code> installed you will have to download it as follows <code>python3 -m pip install --user virtualenv</code></p>
</aside>
<aside class="special"><p> If you are running this on WSL/Linux you can use <code>python3-venv</code> instead and its installed as follows <code>apt-get install python3-venv</code></p>
</aside>
</li>
<li>Activate virtual environment<pre><code>source venv/bin/activate
</code></pre>
<aside class="special"><p> On windows activate it as follows <code>venv/Scripts/activate</code></p>
</aside>
<aside class="warning"><p> This virtual environment is session lived; i.e. if you open a new session you will have to activate the virtual environment again</p>
</aside>
</li>
<li>Install solace agent mesh<pre><code>pip install solace-agent-mesh
</code></pre>
<aside class="special"><p> Since you activated the virtual environment, you can use <code>pip</code> instead of <code>pip3</code> and <code>python</code> instead of <code>python3</code> since everything is within the virtual env session. You can confirm this by running</p>
<pre><code>python --version
</code></pre>
</aside>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Initialize SAM" duration="10">
        <p>In the same directory, run the following</p>
<pre><code>sam init --gui
</code></pre>
<p class="image-container"><img alt="SAM Init" src="img/99ed3b471249c035.png"></p>
<ol type="1">
<li>From here, choose &#34;Advanced Setup&#34; to spin up an instance of the Agent Mesh that uses the Solace Broker as the communication backbone.<aside class="warning"><p> Note that the simple setup &#34;Getting Started Quickly&#34; spins up Agent Mesh without the Solace Broker and uses in-memory queues instead. This is not meant for production ready development and proof of concept project that require high performance and multiple Agentic workflow interactions.</p>
</aside>
</li>
<li>Choose a namespace for your project<img alt="Namespace" src="img/46a4e662f777fe66.png"><aside class="special"><p> The namespace will act as the topic root for all events in SAM</p>
</aside>
</li>
<li>Configure connection to the Solace Broker<img alt="Broker" src="img/5eee67a4eed5e444.png"><aside class="special"><p> Note: If you are using a Solace Cloud instance, you can get the connection parameters from the connect tab after spinning up a Broker Service. Use the Solace Web Messaging Protocol</p>
</aside>
<aside class="special"><p> If you are running a local broker on a docker container with SAM Enterprise in a docker container as well, we will configure this in the following steps to leverage docker network</p>
</aside>
</li>
<li>Configure your LLM endpoint, API Key, and Model name<img alt="LLM Endpoint" src="img/15466a6a62fe3719.png"><aside class="special"><p> The model of choice impact the performance of your results and system behaviour. A performative model is recommended for advanced use-cases</p>
</aside>
<ul>
<li>From the LLM Provider, chose <code>OpenAI Compatible Provider</code></li>
<li>Use <code>https://lite-llm.mymaas.net</code> as your LLM Endpoint URL</li>
<li>If you do not have a token, ask Solace Chat to generate a token for you. Navigate to <a href="https://solacechat.mymaas.net/" target="_blank">https://solacechat.mymaas.net/</a>. Note: If that doesnt work use <a href="https://solacechatbeta.mymaas.net/" target="_blank">https://solacechatbeta.mymaas.net/</a></li>
<li>Choose a model of choice. You can search for the model. Search for <em>gpt</em> and choose <code>azure-gpt-4o</code></li>
</ul>
</li>
<li>Configure the orchestrator agent<img alt="orchestrator" src="img/5e94f0f5ef157c0a.png"><aside class="special"><p> Keep all the configuration parameters as default. You can explore the other options for configuring the orchestrator agent to see what you have available for fine tuning the behaviour</p>
</aside>
</li>
<li>Configure the WebUI Gateway <img alt="gateway" src="img/80457de2c9d0c31f.png"><aside class="special"><p> Note: Choose any Session Secret Key needed for the WebUI. Keep the remaining configurations as default.</p>
</aside>
<aside class="special"><p> If you are running a local broker on a docker container with SAM Enterprise in a docker container as well, we will configure this in the following steps</p>
</aside>
</li>
</ol>
<p>Finalize the last steps and close the browser window when initialization is done.</p>
<p>Now back to your terminal window, lets investigate the directories. Open your directory in your favourite editor</p>
<p class="image-container"><img alt="vscode" src="img/6dd2627073232e51.png"></p>
<ol type="1">
<li><code>configs</code>: contains yaml config files <ul>
<li>agents –&gt; e.g. <code>main_orchestrator.yaml</code></li>
<li>gateways –&gt; e.g. <code>webui.yaml</code></li>
</ul>
</li>
<li><code>venv</code>: contains all python packages</li>
<li><code>.env</code>: environment variables</li>
<li><code>.sam</code>: plugins templates</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Start SAM Enterprise" duration="10">
        <p>This step is involved with running SAM enterprise with the new files generated.</p>
<ol type="1">
<li>Create a docker network bridge such that your SAM container can communicate with your Solace Broker container<pre><code>docker network connect sam-network solace
</code></pre>
<aside class="special"><p>aside Positive skip this step if you are connecting to a cloud hosted broker</p>
</aside>
</li>
<li>Create a <code>docker-compose.yaml</code> file with the following content<pre><code language="language-yaml" class="language-yaml">services:
    sam-ent:
        image: solace-agent-mesh-enterprise:1.0.37
        container_name: sam-ent
        platform: linux/amd64
        # entrypoint: /bin/bash
        stdin_open: true       # same as -it
        tty: true              # same as -it
        volumes:
        - ./configs:/app/configs
        - ./.env:/app/.env
        - ./enterprise-logs:/app  # Map the entire /app directory to enterprise-logs

        networks:
        - sam-network
        ports:
        - &#34;0.0.0.0:8001:8001&#34;        # expose container port 8001 as port 8001 on host IP 0.0.0.0

networks:
    sam-network:
        external: true          # reuse your existing network

</code></pre>
Notes:<ul>
<li>Update the image <code>name:tag</code> to what you your image is called. Execute <code>docker images</code> to get a list.</li>
<li><code>platform: linux/amd64</code> if you are running on mac</li>
<li><code>networks: sam-network</code> if you are attempting to connect to a local solace broker running on docker</li>
<li>We are passing the <code>configs</code> directory and <code>.env</code> file as volumes to the container</li>
<li>We are placing all the sam logs created in the container to a local directory called <code>enterprise-logs</code></li>
<li>the <code>networks</code> section could be removed if you skipped previous step of creating a docker bridge</li>
</ul>
<aside class="special"><p> There are two modes of operation for SAM</p>
<ol type="1">
<li>Connect with broker (Cloud or Software)</li>
<li>Run without broker (Dev Mode)</li>
</ol>
</aside>
</li>
<li>Create a directory called <code>enterprise-logs</code><pre><code>mkdir enterprise-logs
</code></pre>
</li>
<li>[Optional] Run local solace broker (alternatively: use Solace Cloud)<pre><code>docker run -d -p 8080:8080 -p 55554:55555 -p 8008:8008 -p 8000:8000 -p 1883:1883 -p 5672:5672 -p 9000:9000 -p 2222:2222 --shm-size=2g --env username_admin_globalaccesslevel=admin --env username_admin_password=admin --name=solace solace/solace-pubsub-standard
</code></pre>
</li>
<li>Add the solace broker container to the same SAM network<pre><code>docker network connect sam-network solace
</code></pre>
</li>
<li>Open <code>.env</code> file and make the following changes<ul>
<li><code>SOLACE_BROKER_URL="ws://solace:8008"</code> - Update the broker URL to use the solace broker container</li>
<li><code>FASTAPI_HOST="0.0.0.0"</code> - This where the webUI Gateway is hosted on the SAM Enterprise container. We change it to <code>0.0.0.0</code> to make sure its accessed by host IP</li>
<li><code>FASTAPI_PORT="8001"</code>- In case your solace broker has port 8000 exposed</li>
</ul>
This is the final <code>.env</code> file<pre><code>LLM_SERVICE_ENDPOINT=&#34;https://lite-llm.mymaas.net&#34;
LLM_SERVICE_API_KEY=&#34;&lt;llm_token_goes_here&gt;&#34;
LLM_SERVICE_PLANNING_MODEL_NAME=&#34;openai/azure-gpt-4o&#34;
LLM_SERVICE_GENERAL_MODEL_NAME=&#34;openai/azure-gpt-4o&#34;
NAMESPACE=&#34;bootcamp/&#34;
SOLACE_BROKER_URL=&#34;ws://solace:8008&#34;
SOLACE_BROKER_VPN=&#34;default&#34;
SOLACE_BROKER_USERNAME=&#34;default&#34;
SOLACE_BROKER_PASSWORD=&#34;default&#34;
SOLACE_DEV_MODE=&#34;false&#34;
SESSION_SECRET_KEY=&#34;temp&#34;
FASTAPI_HOST=&#34;0.0.0.0&#34;
FASTAPI_PORT=&#34;8001&#34;
FASTAPI_HTTPS_PORT=&#34;8443&#34;
SSL_KEYFILE=&#34;&#34;
SSL_CERTFILE=&#34;&#34;
SSL_KEYFILE_PASSWORD=&#34;&#34;
ENABLE_EMBED_RESOLUTION=&#34;True&#34;
LOGGING_CONFIG_PATH=&#34;configs/logging_config.ini&#34;
S3_BUCKET_NAME=&#34;&#34;
S3_ENDPOINT_URL=&#34;&#34;
S3_REGION=&#34;us-east-1&#34;
WEB_UI_GATEWAY_DATABASE_URL=&#34;sqlite:////Users/tamimi/sam-bootcamp/data/webui_gateway.db&#34;
</code></pre>
<aside class="special"><p> Note that the specific model identifier that the endpoint expects in the format of <code>provider/model</code> (e.g., <code>openai/gpt-4</code>, <code>anthropic/claude-3-opus-20240229</code>).</p>
</aside>
</li>
<li>Run docker compose<pre><code>docker compose up 
</code></pre>
<aside class="special"><p> When the Solace Enterprise container runs, the entry point command for the container is <code>sam run</code>. What this command does is go through all the yaml configuration files under the configs dir and run them. At this point its only the orchestrator agent and web UI gateway.</p>
</aside>
<aside class="special"><p> The docker compose file makes sure port <code>8001</code> from the container is exposed to port <code>8001</code> on the host</p>
</aside>
</li>
<li>Open your browser and navigate to <a href="http://localhost:8001/" target="_blank">http://localhost:8001/</a><img alt="chat" src="img/6d4b700109b5eaf2.png"></li>
</ol>
<p>Try the following prompts:</p>
<pre><code>Give me a list of all the agents in the system
What are the tools you have access to

</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="What is happening in the broker?" duration="1">
        <p>When SAM runs, it configures a couple of queues with subscriptions.</p>
<ol type="1">
<li>Navigate to your broker admin console (e.g. <a href="http://localhost:8080" target="_blank">http://localhost:8080</a>)</li>
<li>Look at the created queues</li>
<li>Look at the subscriptions on each queue</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Adding agents with built-in tools" duration="10">
        <p>Now that you have a docker image running the enterprise edition of SAM, lets go ahead and add configuration files.</p>
<h2 is-upgraded>Basic Agents</h2>
<ol type="1">
<li>From a new terminal window, navigate to your configs directory<pre><code>cd sam-bootcamp/configs/agents
</code></pre>
</li>
<li>Add an agent file that leverages internal tools<pre><code>curl https://raw.githubusercontent.com/SolaceLabs/solace-agent-mesh/refs/heads/main/examples/agents/a2a_agents_example.yaml -o a2a_agents.yaml
</code></pre>
</li>
<li>Restart the enterprise container<pre><code>docker restart sam-ent
</code></pre>
<aside class="special"><p> This restarts the SAM enterprise image with a new config agent config file Pro tip: you can interactively go into the by executing the following</p>
<pre><code>docker exec -it sam-ent bash
</code></pre>
</aside>
</li>
</ol>
<p>This file contains multiple agent configuration that leverages built-in tools. Go ahead and open this file lets inspect it. Here is an example section from the file</p>
<pre><code language="language-yaml" class="language-yaml"> - name: markitdown_agent_app
    app_base_path: .
    app_module: solace_agent_mesh.agent.sac.app
    broker:
      &lt;&lt;: *broker_connection

    # --- App Level Config ---
    app_config:
      namespace: ${NAMESPACE}
      supports_streaming: true
      agent_name: &#34;MarkitdownAgent&#34;
      display_name: &#34;Markdown Creator&#34;
      model: *multimodal_model # Or *planning_model, choose as appropriate
      instruction: |
        The MarkitdownAgent has the following capability:
        * convert various file types (like PDF, DOCX, XLSX, HTML, CSV, PPTX, ZIP) to Markdown.
        Any files you get that might be useful should be saved using create_artifact.
        There is no need to provide a preview of the content in the response.

      # --- Tools Definition ---
      tools:
        - tool_type: builtin
          tool_name: &#34;convert_file_to_markdown&#34;
        - tool_type: builtin-group
          group_name: &#34;artifact_management&#34;

      session_service:
        type: &#34;memory&#34;
        default_behavior: &#34;PERSISTENT&#34; # Or &#34;RUN_BASED&#34;

      artifact_service:
        type: &#34;filesystem&#34;
        base_path: &#34;/tmp/samv2&#34;
        artifact_scope: namespace
      artifact_handling_mode: &#34;reference&#34;
      enable_embed_resolution: true
      enable_artifact_content_instruction: true

      # --- Agent Card Definition ---
      agent_card:
        description: &#34;An agent that converts various file types (like PDF, DOCX, XLSX, HTML, CSV, PPTX, ZIP) to Markdown format.&#34;
        defaultInputModes: [&#34;text&#34;, &#34;file&#34;] # Can take files as input
        defaultOutputModes: [&#34;text&#34;, &#34;file&#34;] # Outputs markdown file
        skills:
        - id: &#34;convert_file_to_markdown&#34;
          name: &#34;Markdown Converter&#34;
          description: &#34;Converts various file types to Markdown format.&#34;

      # --- Discovery &amp; Communication ---
      agent_card_publishing: { interval_seconds: 10 }
      agent_discovery: { enabled: false }
      inter_agent_communication:
        allow_list: []
        request_timeout_seconds: 60
</code></pre>
<p>Notes:</p>
<ul>
<li>Name of the agent is markitdown_agent_app</li>
<li>Uses the <code>convert_file_to_markdown</code> built-in tool and the <code>artifact_management</code> group of tools <pre><code language="language-yaml" class="language-yaml">tools:
    - tool_type: builtin
      tool_name: &#34;convert_file_to_markdown&#34;
    - tool_type: builtin-group
      group_name: &#34;artifact_management&#34;
</code></pre>
</li>
<li>Configures the agent card by exposing the <em>skills</em> this agent is capable of doing: <pre><code language="language-yaml" class="language-yaml">skills:
    - id: &#34;convert_file_to_markdown&#34;
      name: &#34;Markdown Converter&#34;
      description: &#34;Converts various file types to Markdown format.&#34;
</code></pre>
</li>
<li>Adds instructions to SAM on what this agent does <pre><code language="language-yaml" class="language-yaml">instruction: |
    The MarkitdownAgent has the following capability:
    * convert various file types (like PDF, DOCX, XLSX, HTML, CSV, PPTX, ZIP) to Markdown.
    Any files you get that might be useful should be saved using create_artifact.
    There is no need to provide a preview of the content in the response.
</code></pre>
</li>
</ul>
<h2 is-upgraded>Adding a multimedia agent</h2>
<p>Lets add another multi-modal agent. This agent is capable of generating and processing content in both audio and visual formats. It includes features like text-to-speech with tone-based voice selection, multi-speaker conversations, audio transcription, image generation, and image analysis, while providing detailed guidelines for using these features effectively.</p>
<p>In the <code>configs/agents</code> directory</p>
<ol type="1">
<li>Add an agent file that leverages internal tools<pre><code>curl https://raw.githubusercontent.com/SolaceLabs/solace-agent-mesh/refs/heads/main/examples/agents/a2a_multimodal_example.yaml -o multimodal.yaml
</code></pre>
</li>
<li>Shared<pre><code>image_describe: &amp;image_description_model
  # This dictionary structure tells ADK to use the LiteLlm wrapper.
  # &#39;model&#39; uses the specific model identifier your endpoint expects.
  model: ${IMAGE_DESCRIPTION_MODEL_NAME} # Use env var for model name
  # &#39;api_base&#39; tells LiteLLM where to send the request.
  api_base: ${IMAGE_SERVICE_ENDPOINT} # Use env var for endpoint URL
  # &#39;api_key&#39; provides authentication.
  api_key: ${IMAGE_SERVICE_API_KEY} # Use env var for API key

audio_transcription: &amp;audio_transcription_model
  # This dictionary structure tells ADK to use the LiteLlm wrapper.
  # &#39;model&#39; uses the specific model identifier your endpoint expects.
  model: ${AUDIO_TRANSCRIPTION_MODEL_NAME} # Use env var for model name
  # &#39;api_base&#39; tells LiteLLM where to send the request.
  api_base: ${AUDIO_TRANSCRIPTION_API_BASE} # Use env var for endpoint URL
  # &#39;api_key&#39; provides authentication.
  api_key: ${AUDIO_TRANSCRIPTION_API_KEY} # Use env var for API key
</code></pre>
</li>
<li>Update yor env file with the following environment variable<pre><code>GEMINI_API_KEY=&lt;token&gt;
</code></pre>
<aside class="special"><p> Ask your instructor for a Gemini key or generate one from <a href="aistudio.google.com" target="_blank">aistudio.google.com</a></p>
</aside>
</li>
<li>Restart the enterprise container<pre><code>docker restart sam-ent
</code></pre>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Adding MCP Agent" duration="5">
        <p>To add an MCP agent, we will simply define an agent yaml file with the basic configuration. In this step, we will go ahead and add a <a href="https://github.com/cablate/mcp-google-map" target="_blank">Google Maps MCP Agent</a>.</p>
<h2 is-upgraded>Add Agent File</h2>
<ol type="1">
<li>Create a new file under <code>configs/agents</code><pre><code>cd configs/agents
touch google_maps_mcp.yaml
</code></pre>
</li>
<li>Open that file and place the following content in the file<pre><code language="language-yaml" class="language-yaml"># Solace AI Connector: Agent Configuration Template
log:
stdout_log_level: INFO
log_file_level: DEBUG
log_file: a2a_agent.log

!include ../shared_config.yaml

apps:
- name: &#34;GoogleMaps__app&#34;
    app_base_path: .
    app_module: solace_agent_mesh.agent.sac.app
    broker:
    &lt;&lt;: *broker_connection

    # App Level Config
    app_config:
    namespace: &#34;${NAMESPACE}&#34; # Your A2A topic namespace
    supports_streaming: true # Host capability flag
    agent_name: &#34;GoogleMaps&#34;
    # The model will be an alias like *planning_model, *general_model etc.
    # The python script will replace *general_model with the correct alias string.
    model: *general_model 

    instruction: | # User-provided instruction
        TO BE FILLED

    tools: 
        ## TO BE FILLED

    session_service: *default_session_service
    artifact_service: *default_artifact_service

    artifact_handling_mode: &#34;embed&#34; # How to handle artifacts
    enable_embed_resolution: true # Enable embed feature and instruction injection
    enable_artifact_content_instruction: true # Enable instruction for late-stage embed
    enable_builtin_artifact_tools: # Enable artifact tools and instruction injection
        enabled: true
    enable_builtin_data_tools: # Enable data analysis tools and instruction injection
        enabled: false
    data_tools_config: *default_data_tools_config # Use the default data tools config

    # Agent Card Definition
    agent_card:
        description: &#34;TO BE FILLED&#34;
        defaultInputModes: [text] 
        defaultOutputModes: [text, file] 
        skills: []

    # Discovery &amp; Communication
    agent_card_publishing: 
        interval_seconds: 10
    agent_discovery: 
        enabled: true
    inter_agent_communication:
        allow_list: [&#34;&#34;] 
        deny_list: [] 
        request_timeout_seconds: 180
</code></pre>
</li>
<li>Update the <code>instruction</code> section with the following<pre><code language="language-yaml" class="language-yaml">    You are a Google Maps MCP server with the following capabilities:

    1. Location Search
    - Search for places near a specific location with customizable radius and filters
    - Get detailed place information including ratings, opening hours, and contact details

    2. Geocoding Services
    - Convert addresses to coordinates (geocoding)
    - Convert coordinates to addresses (reverse geocoding)

    3. Distance &amp; Directions
    - Calculate distances and travel times between multiple origins and destinations
    - Get detailed directions between two points with step-by-step instructions
    - Support for different travel modes (driving, walking, bicycling, transit)

    4. Elevation Data
    - Retrieve elevation data for specific locations
</code></pre>
</li>
<li>Update the tools section with the following:<pre><code language="language-yaml" class="language-yaml">tools: 
    - group_name: artifact_management
      tool_type: builtin-group
    - group_name: general
      tool_type: builtin-group
    - connection_params:
        args:
        - -y
        - &#39;@cablate/mcp-google-map&#39;
        command: npx
        type: stdio
      environment_variables:
        GOOGLE_MAPS_API_KEY: ${GOOGLE_MAPS_API_KEY} 
      tool_type: mcp
</code></pre>
A couple of things to point out:<ul>
<li>This Agent leverages two built-in tools <code>artifact_management</code> and the <code>general</code> builtin-group</li>
<li>Also uses tools exposed by a local MCP server as configured via <code>tool_type: mcp</code></li>
<li>The MCP server runs locally as per the <a href="https://github.com/cablate/mcp-google-map" target="_blank">Google Maps MCP Agent Documentation</a></li>
<li>An env var is required for this MCP server as defined in <code>environment_variables</code></li>
</ul>
</li>
</ol>
<p>The final config file looks like this</p>
<pre><code language="language-yaml" class="language-yaml">log:
  stdout_log_level: INFO
  log_file_level: DEBUG
  log_file: a2a_agent.log

!include ../shared_config.yaml

apps:
  - name: &#34;GoogleMaps__app&#34;
    app_base_path: .
    app_module: solace_agent_mesh.agent.sac.app
    broker:
      &lt;&lt;: *broker_connection

    # App Level Config
    app_config:
      namespace: &#34;${NAMESPACE}&#34; # Your A2A topic namespace
      supports_streaming: true # Host capability flag
      agent_name: &#34;GoogleMaps&#34;
      # The model will be an alias like *planning_model, *general_model etc.
      # The python script will replace *general_model with the correct alias string.
      model: *general_model 

      instruction: | # User-provided instruction
        You are a Google Maps MCP server with the following capabilities:

        1. Location Search
        - Search for places near a specific location with customizable radius and filters
        - Get detailed place information including ratings, opening hours, and contact details

        2. Geocoding Services
        - Convert addresses to coordinates (geocoding)
        - Convert coordinates to addresses (reverse geocoding)

        3. Distance &amp; Directions
        - Calculate distances and travel times between multiple origins and destinations
        - Get detailed directions between two points with step-by-step instructions
        - Support for different travel modes (driving, walking, bicycling, transit)

        4. Elevation Data
        - Retrieve elevation data for specific locations
      
      tools: 
        - group_name: artifact_management
          tool_type: builtin-group
        - group_name: general
          tool_type: builtin-group
        - connection_params:
            args:
            - -y
            - &#39;@cablate/mcp-google-map&#39;
            command: npx
            type: stdio
          environment_variables:
            GOOGLE_MAPS_API_KEY: ${GOOGLE_MAPS_API_KEY} 
          tool_type: mcp

      session_service: *default_session_service
      artifact_service: *default_artifact_service
      
      artifact_handling_mode: &#34;embed&#34; # How to handle artifacts
      enable_embed_resolution: true # Enable embed feature and instruction injection
      enable_artifact_content_instruction: true # Enable instruction for late-stage embed
      enable_builtin_artifact_tools: # Enable artifact tools and instruction injection
        enabled: true
      enable_builtin_data_tools: # Enable data analysis tools and instruction injection
        enabled: false
      data_tools_config: *default_data_tools_config # Use the default data tools config

      # Agent Card Definition
      agent_card:
        description: &#34;Google Maps MCP server with the following capabilities: Location Search, Geocoding Services, Distance &amp; Directions, Elevation Data.&#34;
        defaultInputModes: [text] 
        defaultOutputModes: [text, file] 
        skills: []
      
      # Discovery &amp; Communication
      agent_card_publishing: 
        interval_seconds: 10
      agent_discovery: 
        enabled: true
      inter_agent_communication:
        allow_list: [] 
        deny_list: [] 
        request_timeout_seconds: 180
</code></pre>
<h2 is-upgraded>Add Env var</h2>
<p>Edit your .env file to add a <code>GOOGLE_MAPS_API_KEY</code></p>
<pre><code language="language-yaml" class="language-yaml">GOOGLE_MAPS_API_KEY=&#34;YOUR_API_KEY&#34;
</code></pre>
<h2 is-upgraded>Restart Enterprise docker</h2>
<pre><code>docker restart sam-ent
</code></pre>
<p>Now navigate to your SAM instance on <a href="http://localhost:8001/" target="_blank">http://localhost:8001/</a> and see the new agent added</p>


      </google-codelab-step>
    
      <google-codelab-step label="Adding Agent with Web GUI" duration="5">
        <pre><code>sam add agent --gui
</code></pre>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
