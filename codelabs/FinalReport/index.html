
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Final Project Report – Web App</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="FinalReport"
                  title="Final Project Report – Web App"
                  environment="web"
                  feedback-link="https://github.com/SolaceDev/solace-dev-codelabs/blob/master/markdown/FinalReport">
    
      <google-codelab-step label="About This Project" duration="0">
        <p>The source code of Google Cloud APIs is in backend folder, and the source code of streamlit is in streamlit folder. The streamlit app is also deployed on Google Cloud Platform.</p>
<p>If you want to get a FastAPI + Streamlit version, you can see this <a href="https://github.com/pngchen/CSYE7245/tree/main/finalProject" target="_blank">GitHub</a>. But it is a old version, I have updated several versions only on Google Cloud Platform, because of the  time limitation. So FastAPI + Streamlit version is different from GCP version. And FastAPI + Streamlit version and GCP version are unrunnable, because I didn&#39;t upload the GCP credential json file. You can try to use your own GCP credential json file to run this code. And you can get your GCP keys according to <a href="https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-python" target="_blank">Creating and managing service account keys</a>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="How to Use" duration="0">
        <p>You can visit the website by <a href="https://hardy-portal-318606.de.r.appspot.com/" target="_blank">https://hardy-portal-318606.de.r.appspot.com/</a>.</p>
<h2 is-upgraded>Synthetic App</h2>
<p>In <strong><em>Choose an appliocation</em></strong>, if you choose the <strong><em>Synthetic</em></strong>, the website will look like below without result part. Then you can input the index which you want to generate a VIL file, and choose a synthetic model. After that, you can click the <strong><em>Synthetic</em></strong> button.</p>
<p class="image-container"><img alt="Synthetic App" src="img/1fa994f7d5ad89ad.png"></p>
<p>Finally, you can get your result. The <strong>b96b766e-2859-4ea7-80a1-e01a096c8d87.pkl</strong> is the VIL file generated by synthetic model. And the <strong>3ef16f03-bedc-4c41-8d42-4830f6d6570c.png</strong> is the result figure.</p>
<h2 is-upgraded>Nowcast App</h2>
<p>In <strong><em>Choose an appliocation</em></strong>, if you choose the <strong><em>Nowcast</em></strong>, and if you already have a VIL file, you can click the <strong><em>Yes</em></strong> button in <strong><em>Already have a VIL file</em></strong> part. Then you can input your VIL file name, for example, you generated a VIL file in Synthetic step just now, the file name is <strong>b96b766e-2859-4ea7-80a1-e01a096c8d87.pkl</strong>. You can input that and choose the index and nowcast model. You can see the picture below.</p>
<p class="image-container"><img alt="Nowcast1 App" src="img/4036b90da84ce02d.png"></p>
<p>Finally, you can get the <strong>db925129-a609-45a6-9172-4abc9cd3dc09.png</strong> as your result.</p>
<p>If you don&#39;t have a VIL file, you can click the <strong><em>No</em></strong> button in <strong><em>Already have a VIL file</em></strong> part. Then you can follow the steps above to do synthetic and nowcast together. You can see the example in figure below.</p>
<p class="image-container"><img alt="Nowcast2 App" src="img/854154c1b064104.png"></p>
<p>Note: If you see the picture in the website is broken, you can copy the image file name, and in <strong><em>Choose an appliocation</em></strong>, choose <strong><em>View Image</em></strong>, then paste the image name into the input box and press Enter.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Technical Overview" duration="0">
        <p class="image-container"><img alt="Diagram" src="img/89ca38d61d136c70.png"></p>
<p>I pushed <code>get_syn</code> function by <code>gcloud functions deploy get_syn --runtime python37 --memory 4096MB --timeout 500s --trigger-http --allow-unauthenticated</code> as a Google Cloud Function. And the source code of the <code>get_syn</code> is following:</p>
<pre><code language="language-python" class="language-python">def get_syn(request):
    request_json = request.get_json(silent=True)
    request_args = request.args

    if request_json and &#39;modelName&#39; in request_json and &#39;idx&#39; in request_json:
        modelName = request_json[&#39;modelName&#39;]
        idx = int(request_json[&#39;idx&#39;])
    elif request_args and &#39;modelName&#39; in request_args and &#39;idx&#39; in request_args:
        modelName = request_args[&#39;modelName&#39;]
        idx = int(request_args[&#39;idx&#39;])

    FS = gcsfs.GCSFileSystem(project=&#34;Assignment1&#34;,
                             token=&#34;hardy-portal-318606-3c8e02bd3a5d.json&#34;)
    model = config.synthetics[modelName]

    with FS.open(f&#39;gs://assignment1-data/models/synrad/{model}.h5&#39;, &#39;rb&#39;) as model_file:
        model_gcs = h5py.File(model_file, &#39;r&#39;)
        model = tf.keras.models.load_model(model_gcs, compile=False, custom_objects={&#34;tf&#34;: tf})

    x_test, y_test = syntheticData.get_data(idx)

    y_pred = synthetic.run_synrad(model, x_test)

    imgname, pklname = synthetic.main(modelName, x_test, y_test, y_pred)

    return {&#34;imgname&#34;: imgname, &#34;pklname&#34;: pklname}
</code></pre>
<p>And then I also pushed <code>get_nowcast</code> function by <code>gcloud functions deploy get_nowcast --runtime python37 --memory 4096MB --timeout 500s --trigger-http --allow-unauthenticated</code> as a Google Cloud Function. The source code is following:</p>
<pre><code language="language-python" class="language-python">def get_nowcast(request):
    request_json = request.get_json(silent=True)
    request_args = request.args

    if request_json and &#39;modelName&#39; in request_json and &#39;pklname&#39; in request_json and &#39;idx&#39; in request_json:
        modelName = request_json[&#39;modelName&#39;]
        pklname = request_json[&#39;pklname&#39;]
        idx = int(request_json[&#39;idx&#39;])
    elif request_args and &#39;modelName&#39; in request_args and &#39;pklname&#39; in request_args and &#39;idx&#39; in request_args:
        modelName = request_args[&#39;modelName&#39;]
        pklname = request_args[&#39;pklname&#39;]
        idx = int(request_args[&#39;idx&#39;])

    FS = gcsfs.GCSFileSystem(project=&#34;Assignment1&#34;,
                             token=&#34;hardy-portal-318606-3c8e02bd3a5d.json&#34;)
    model = config.models[modelName]

    with FS.open(f&#39;gs://assignment1-data/models/nowcast/{model}.h5&#39;, &#39;rb&#39;) as model_file:
        model_gcs = h5py.File(model_file, &#39;r&#39;)
        model = tf.keras.models.load_model(model_gcs, compile=False, custom_objects={&#34;tf&#34;: tf})

    x_test, y_test = dataPipeline.run(pklname)

    name = nowcast.visualize_result(model, x_test, y_test, idx, modelName)

    return {&#34;name&#34;: name}
</code></pre>
<p>Finally, I deployed my steamlit app on Google Cloud by <code>gcloud app deploy app.yaml</code>. You can visit the website by <a href="https://hardy-portal-318606.de.r.appspot.com/" target="_blank">https://hardy-portal-318606.de.r.appspot.com/</a>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Pipeline Detail" duration="0">
        <h2 is-upgraded>Prepare the Data Catalog</h2>
<p>I didn&#39;t upload all of the sevir data to Google Cloud Platform, because of the extremely large data size. So I have cleaned the <strong>Catalog.csv</strong> file, retaining only the data which have ir069, ir107, lght, vil and vis files. After that, there are only 236 storm events remained in <strong>Catalog.csv</strong>. That&#39;s why, the input index of synthetic part should be from 0 to 235.</p>
<h2 is-upgraded>Synthetic App</h2>
<h3 is-upgraded>Overview</h3>
<p class="image-container"><img alt="Synthetic App Pipeline" src="img/df603092d22cd9db.png"></p>
<h3 is-upgraded>Detail</h3>
<ul>
<li>Input the data index and synthetic model name by user;</li>
<li>Get the input information by streamlit app;</li>
<li><code>get_syn</code> API called by streamlit app: <ul>
<li><code>get_syn</code> function will find the storm data in <strong>Catalog.csv</strong> according to the data index passed by streamlit app;</li>
<li>Get the vil, ir069, ir107 and lght file name of target storm event data, and the event index in these files (more detail, you can see the picture below); <img alt="dataExample1" src="img/714c4abae2b88833.png"></li>
<li>Transform the data shape, in order to input to synthetic model: <ul>
<li>Vil data: (384, 384, 49) –&gt; (49, 384, 384, 1);</li>
<li>Lght data: (2267, 5) –&gt; (49, 48, 48, 1);</li>
<li>Ir069 data: (192, 192, 49) –&gt; (49, 192, 192, 1);</li>
<li>Ir107 data: (192, 192, 49) –&gt; (49, 192, 192, 1);</li>
</ul>
</li>
<li>Using transformed data as input to synthetic model assigned by user, generate vil file;</li>
<li>Transform vil data: (49, 384, 384, 1) –&gt; (384, 384, 49), save the data as a pickle file and save the visualized data as a png file in Google Cloud Bucket;</li>
<li>Return the pickle file name and png file name;</li>
</ul>
</li>
<li>Get the pickle file name and png file name by streamlit app and show the image.</li>
</ul>
<h2 is-upgraded>Nowcast App</h2>
<h3 is-upgraded>Overview</h3>
<p class="image-container"><img alt="Nowcast App Pipeline" src="img/afece91e689b5994.png"></p>
<h3 is-upgraded>Detail</h3>
<ul>
<li>Input the data index and nowcast model name (and vil file name) by user;</li>
<li>Get the input information by streamlit app;</li>
<li><code>get_nowcast</code> API called by streamlit app: <ul>
<li><code>get_nowcast</code> function will load the vil data passed by streamlit app;</li>
<li>Split vil data from (384, 384, 49) to X: (384, 384, 13) and Y: (384, 384, 12): <pre><code language="language-python" class="language-python">Event Frames:  [-----------------------------------------------]
               [----13-----][---12----]
                 [----13----][----12----]
                   [-----13----][----12----]
                     ...  in total 25 (x, y)s
                                     [-----13----][----12----]
                                       [-----13----][----12----]
</code></pre>
</li>
<li>Using the split data as input to nowcast model assigned by user, generate the prediction data;</li>
<li>Save visualized prediction data as a png file in Google Cloud Bucket.</li>
<li>Return the png file name;</li>
</ul>
</li>
<li>Get png file name by streamlit app and show the image.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Reference" duration="0">
        <ul>
<li><a href="https://testdriven.io/blog/fastapi-streamlit/" target="_blank">Serving a Machine Learning Model with FastAPI and Streamlit</a></li>
<li><a href="https://towardsdatascience.com/deploying-streamlit-apps-to-gcp-79ad5933013e" target="_blank">Deploying Streamlit Apps to GCP</a></li>
<li><a href="https://cloud.google.com/functions/docs/first-python#testing_the_function" target="_blank">Your First Function: Python</a></li>
<li><a href="https://cloud.google.com/functions/docs/writing" target="_blank">Writing Cloud Functions</a></li>
<li><a href="https://medium.com/analytics-vidhya/how-to-load-keras-h5-model-format-from-google-cloud-bucket-abf9a77d3cb4" target="_blank">How to load Keras h5 model format from Google Cloud Bucket</a></li>
<li><a href="https://nbviewer.jupyter.org/github/MIT-AI-Accelerator/eie-sevir/blob/master/examples/SEVIR_Tutorial.ipynb" target="_blank">SEVIR Tutorial</a></li>
<li><a href="https://github.com/MIT-AI-Accelerator/neurips-2020-sevir" target="_blank">neurips-2020-sevir</a></li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
